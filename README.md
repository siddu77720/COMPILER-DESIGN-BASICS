# COMPILER-DESIGN-BASICS

*COMPANY*:COTECH IT SOLUTION

*NAME*:SIDDU.V.SHINDE

*INTERN ID*:CT06DM886

*DOMAIN*: C-PROGRAMMING

*DURATION*:6 WEEKS

*MENTOR*:NEELA SANTOSH

##Description of the Lexical Analyzer Program and Tools Used ğŸ–¥ï¸ğŸ”
A lexical analyzer (or lexer) is the first phase of a compiler in compiler design. It reads the input source code and breaks it down into tokens â€” the smallest meaningful elements like keywords, identifiers, and operators. Our simple lexical analyzer written in C language performs this essential task by scanning through an input file and categorizing each word or symbol accordingly. ğŸ“„âœ¨

Tools Used: OnlineGDB Compiler ğŸ§°ğŸŒ
For developing and testing this lexical analyzer program, I used OnlineGDB (https://www.onlinegdb.com). Itâ€™s a powerful, web-based online compiler and debugger that supports multiple languages including C, C++, Python, and more. This tool is perfect for writing, compiling, running, and debugging code without needing to install any software locally on your computer. ğŸ’»âš¡

Why OnlineGDB?

Accessibility: Accessible from anywhere with an internet connection â€” no installation hassle.

Ease of Use: Clean, simple interface suitable for beginners and experts alike.

Debugger Support: Allows step-by-step debugging, breakpoints, and variable inspection.

File Handling: Supports reading from and writing to files, which is essential for lexical analysis of input source code.

Real-Time Output: You can instantly see program output or errors in the integrated terminal.

Because lexical analyzers usually work on source code files, having file handling capabilities in OnlineGDB makes it convenient to upload your input source code (input.txt) and run the analyzer directly in the browser. ğŸŒğŸ“

How the Lexical Analyzer Works ğŸ”âš™ï¸
Reading Input: The program opens an input file containing the source code and reads it character by character.

Tokenizing: It groups characters into strings (words) whenever it finds a delimiter (like space, newline, or operator).

Classification: Each token is checked if it matches known keywords (like int, if, return), or if itâ€™s an identifier (variable/function names), or an operator (+, -, =, etc.).

Output: The program prints each token along with its category, helping you understand the lexical structure of your code.

Applicability and Importance in Compiler Design ğŸ“šğŸ’¡
Lexical analyzers are fundamental in compiler construction and language processing. Hereâ€™s where this tool is applicable:

Compiler Front-End: Itâ€™s the first phase of every compiler that converts source code into tokens. These tokens are then passed to the parser for syntax analysis.

Syntax Highlighting: Code editors and IDEs use lexical analysis to highlight keywords and symbols differently for better readability.

Code Formatting and Refactoring: Tools that automatically format or refactor code rely on tokenization to understand code structure.

Security Analysis: Lexical analyzers can help identify suspicious or malformed code snippets during static analysis.

Educational Purpose: Itâ€™s an excellent learning project for computer science students to understand how programming languages are parsed and compiled.

Final Thoughts ğŸ’­ğŸš€
Creating a lexical analyzer is an essential step to understanding how programming languages are processed internally. Using an online compiler like OnlineGDB makes the development process accessible and convenient, especially for learners without advanced local setups.

This project bridges theory and practice in compiler design, giving you firsthand experience in building the backbone of many software tools we use daily. Plus, the skills you gain here â€” file handling, string manipulation, pattern recognition â€” are useful across countless programming and development scenarios. ğŸŒŸğŸ’»

#OUTPUT
